{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####  Routines for Pre-processing (Data Wrangling/Data Cleaning) any dataset for further Data Analysis\n",
    "\n",
    "##### IMPORTANT !!! --> Run each block below indivdually, so you can make decisions according to the results \n",
    "#                       to decide to continue with the next block.  \n",
    "\n",
    "\n",
    "####################################  Run this block to load dataset and show data (feature) types\n",
    "file_name = 'name of file'  #<--------inform file here  \n",
    "path = 'file path'          #<--------inform path here \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',None)     # Optional \n",
    "pd.set_option('display.max_rows',None)      # Optional\n",
    "df =pd.read_csv(path+file_name)\n",
    "df.dtypes\n",
    "\n",
    "####################################    Run this block to show first 10 rows of dataset\n",
    "df.head(10)\n",
    "\n",
    "####################################   Run this block to show a summary (distribution) of data (numerical/categorical features)\n",
    "df.describe(include='all')\n",
    "\n",
    "\n",
    "###################################   Run this block to show all features containing missing values, and their percentage proportion\n",
    "allFeatures= []\n",
    "for feature in list(df.columns): \n",
    "    if  len(df[feature].isnull().value_counts()) == 1: # no missing values for this feature\n",
    "        allFeatures.append([feature,0,100]) \n",
    "    else:   \n",
    "        allFeatures.append([feature, df[feature].isnull().value_counts()[True]*100/len(df),df[feature].isnull().value_counts()[False]*100/len(df)])\n",
    "\n",
    "dfShowMissingValues = pd.DataFrame(allFeatures,columns=['features','missing values %','identified values%']).sort_values('missing values %')\n",
    "dfShowMissingValues.reset_index()\n",
    "\n",
    "###################################   Run this block to print all the features to copy-paste below only the ones to be kept\n",
    "print('Get from the list below only the features to be kept:')\n",
    "list(dfShowMissingValues.features)\n",
    "\n",
    "\n",
    "###################################   Run this block to define here the columns to keep \n",
    "columnsToKeep = [] # <----Copy inside this brackets (from what was printed above), only the features to be kept\n",
    "print('Features that will be kept:')\n",
    "columnsToKeep\n",
    "\n",
    "##################################   Run this block to show columns that were kept, but still have missing values (grouped by data type)\n",
    "dfcolumnsWithMissingValuesToKeep = pd.Series(df[columnsToKeep].isnull().any().index)[list(df[columnsToKeep].isnull().any())]\n",
    "\n",
    "dfMissing = df[dfcolumnsWithMissingValuesToKeep]\n",
    "\n",
    "print('These are the features kept that are still with missing values:')\n",
    "\n",
    "for featureType in dfMissing.dtypes.unique():\n",
    "    print('\\n','-'*40,'\\n********',featureType,'type Features with missing values'.upper(),'\\n','-'*40) \n",
    "    print(dfMissing.dtypes[dfMissing.dtypes == featureType],'\\n','-'*40) \n",
    "    \n",
    "    for feature in dfMissing.dtypes.index[dfMissing.dtypes == featureType]:\n",
    "        print(dfMissing[feature].isnull().value_counts(),'\\n','-'*40) \n",
    "\n",
    "dfFinal = df.copy()[columnsToKeep]\n",
    "\n",
    "\n",
    "#////////////////////// Run this block to replace missing values of ALL numerical features of type (--specify type--) by the average of their columns\n",
    "typeOfNumerical = 'new type' #<------specify type the new type-- Ex: float64\n",
    "\n",
    "print('\\n********',typeOfNumerical,'type Features containing missing values before - values NOW','\\n','-'*40) \n",
    "for feature in list(dfFinal.dtypes[dfFinal.dtypes == typeOfNumerical].index):\n",
    "    dfFinal[feature].replace(np.nan,dfFinal[feature].mean(),inplace=True)\n",
    "    print(dfFinal[feature].isnull().value_counts(),'\\n','-'*40) \n",
    "\n",
    "\n",
    "# ////////////////////// Run this block to replace missing values of a categorical feature (--specify column--) by the most frequent value in the column\n",
    "categoricalColumn = 'name' #<------specify name of categorical column here----\n",
    "\n",
    "dfFinal[categoricalColumn].replace(np.nan,df.describe(include='all')[categoricalColumn].top,inplace=True)\n",
    "print('\\n******** MISSING VALUES OF CATEGORICAL COLUMN',categoricalColumn,'REPLACED WITH THE MOST FREQUENT FOUND ON COLUMN:',df.describe(include='all')[categoricalColumn].top,'\\n','-'*40) \n",
    "print('\\n********',categoricalColumn,'column containing missing values before - values NOW','\\n','-'*40) \n",
    "print(dfFinal[categoricalColumn].isnull().value_counts(),'\\n','-'*40)        \n",
    "    \n",
    "\n",
    "# ////////////////////// Run this block to drop ***ROWS** with missing values on (---specific column---)  \n",
    "columnToCheckMissingValues = ['name'] #<------specify name of column here----\n",
    "\n",
    "print('\\n******** ROWS WITH MISSING VALUES ON COLUMN',columnToCheckMissingValues,' WERE DROPPED !','\\n','-'*40) \n",
    "print('Rows before: ',len(dfFinal),'\\n','-'*40) \n",
    "dfFinal.dropna(subset=columnToCheckMissingValues,axis=0,inplace=True)\n",
    "print('Rows now: ',len(dfFinal),'\\n','-'*40)  \n",
    "    \n",
    "# ////////////////////// Run this block to Drop ****ENTIRE**** column by name (---specify---) \n",
    "columnToBeDropped = ['name'] #<------specify column to drop here----\n",
    "\n",
    "print('Columns before: ',len(dfFinal.columns),dfFinal.columns,'\\n','-'*40) \n",
    "dfFinal.drop(columnToBeDropped,axis=1,inplace=True)\n",
    "print('\\n******** COLUMN',columnToBeDropped,' WAS DROPPED !','\\n','-'*40)\n",
    "print('Columns now: ',len(dfFinal.columns),dfFinal.columns,'\\n','-'*40) \n",
    "\n",
    "#/////////////////////////////Run this block to show remaining features and if there are still missing values for them \n",
    "print(dfFinal.dtypes)\n",
    "print('\\n','-'*40,'\\n','Missing Values\\n','-'*40,'\\n',dfFinal.isnull().any().value_counts())  \n",
    "\n",
    "#///////Format correction///////////////Run this block to correct wrong data types of columns (--specify list, specify new data type)\n",
    "featuresToBeConverted = []#<---specify here Ex: ['population','total_cases','new_cases','new_deaths','total_deaths'] \n",
    "newDataType = 'type'#<---specify here Ex: 'int'\n",
    "\n",
    "print('\\n******** DATA TYPES OF',featuresToBeConverted,' WERE CHANGED !','\\n','-'*40) \n",
    "for feature in featuresToBeConverted:\n",
    "    print(feature,': converted from',dfFinal[feature].dtype,'to ---->')\n",
    "    dfFinal[feature] = dfFinal[feature].astype(newDataType)\n",
    "    print(dfFinal[feature].dtype)\n",
    "dfFinal.dtypes\n",
    "\n",
    "#///////Unit Convertion///////////////Run this block to convert units of columns and change their names as well (--specify lists)\n",
    "featuresToBeConverted = []#<---old column names: Ex: ['total_cases_per_million','new_cases_per_million','new_cases_smoothed_per_million']\n",
    "newNamesToBeReceived = []#<---new column names: Ex: ['total_cases_per_thousand','new_cases_per_thousand','new_cases_smoothed_per_thousand']\n",
    "\n",
    "print('\\n******** UNITS OF COLUMNS',featuresToBeConverted,' WERE CONVERTED, AND NAMES CHANGED TO',newNamesToBeReceived,'\\n','-'*40) \n",
    "for feature in zip(featuresToBeConverted,newNamesToBeReceived):\n",
    "    dfFinal[feature[0]] = #<------ define here the conversion Ex: dfFinal[feature[0]] /=1000 \n",
    "    dfFinal.rename(columns={feature[0]:feature[1]},inplace=True)\n",
    "dfFinal.head()\n",
    "\n",
    "#///////Convention standardisation ///////////////Run this block to standardize a convention for a column (--specify column,old value,new value)\n",
    "feature= 'name' #<------specify column name Ex:'location' \n",
    "value1='old value' #<------specify old value Ex: 'Afghanistan' \n",
    "value2='new value' #<------specify new value Ex: 'AFGHANISTAN' \n",
    "\n",
    "print('\\n******** COLUMN [',feature,'] HAD ITS VALUES CHANGED FROM',value1,'TO',value2,'\\n','-'*40) \n",
    "dfFinal[feature].replace(value1,value2,inplace=True)\n",
    "dfFinal.head()\n",
    "\n",
    "\n",
    "#////////////////////// Run this block to Normalize features \n",
    "typeOfNormalization = 0  #<---specify one of these types: (0) Simple Feature Scaling  (1) Min-max  (2) Z-score\n",
    "featuresToBeNormalized = []#<-----specify features--- Ex:['population_density','life_expectancy']\n",
    "\n",
    "nameOfNormalization = ['Simple Feature Scaling' ,'Min-max','Z-score']\n",
    "\n",
    "print('\\n******** COLUMNS:',featuresToBeNormalized,' WERE NORMALIZED WITH',nameOfNormalization[typeOfNormalization],'\\n','-'*40)  \n",
    "\n",
    "for feature in featuresToBeNormalized:\n",
    "    print(feature,': normalized from range [ %.2f , %.2f]' % (dfFinal[feature].min(),dfFinal[feature].max()))\n",
    "\n",
    "    if  typeOfNormalization == 0:\n",
    "        dfFinal[feature] = dfFinal[feature] / dfFinal[feature].max()\n",
    "    elif typeOfNormalization == 1:\n",
    "        dfFinal[feature] = (dfFinal[feature] - dfFinal[feature].min()) / (dfFinal[feature].max() - dfFinal[feature].min() )  \n",
    "    else: # typeOfNormalization == (2) Z-score        \n",
    "        dfFinal[feature] = (dfFinal[feature] - dfFinal[feature].mean()) / dfFinal[feature].std()       \n",
    "\n",
    "    print('to ----> [ %.2f , %.2f]' % (dfFinal[feature].min(),dfFinal[feature].max()))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
